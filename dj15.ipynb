{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import cm, pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas_datareader import data\n",
    "import keras\n",
    "import ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data.DataReader(\"^DJI\",start='2010-1-1',end='2020-7-30',data_source='yahoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv('DJI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2663"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('DJI.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>10555.009766</td>\n",
       "      <td>10423.129883</td>\n",
       "      <td>10548.509766</td>\n",
       "      <td>10428.049805</td>\n",
       "      <td>137940000</td>\n",
       "      <td>10428.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>10604.969727</td>\n",
       "      <td>10430.690430</td>\n",
       "      <td>10430.690430</td>\n",
       "      <td>10583.959961</td>\n",
       "      <td>179780000</td>\n",
       "      <td>10583.959961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>10584.559570</td>\n",
       "      <td>10522.519531</td>\n",
       "      <td>10584.559570</td>\n",
       "      <td>10572.019531</td>\n",
       "      <td>188540000</td>\n",
       "      <td>10572.019531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>10594.990234</td>\n",
       "      <td>10546.549805</td>\n",
       "      <td>10564.719727</td>\n",
       "      <td>10573.679688</td>\n",
       "      <td>186040000</td>\n",
       "      <td>10573.679688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>10612.370117</td>\n",
       "      <td>10505.209961</td>\n",
       "      <td>10571.110352</td>\n",
       "      <td>10606.860352</td>\n",
       "      <td>217390000</td>\n",
       "      <td>10606.860352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date          High           Low          Open         Close  \\\n",
       "0  2009-12-31  10555.009766  10423.129883  10548.509766  10428.049805   \n",
       "1  2010-01-04  10604.969727  10430.690430  10430.690430  10583.959961   \n",
       "2  2010-01-05  10584.559570  10522.519531  10584.559570  10572.019531   \n",
       "3  2010-01-06  10594.990234  10546.549805  10564.719727  10573.679688   \n",
       "4  2010-01-07  10612.370117  10505.209961  10571.110352  10606.860352   \n",
       "\n",
       "      Volume     Adj Close  \n",
       "0  137940000  10428.049805  \n",
       "1  179780000  10583.959961  \n",
       "2  188540000  10572.019531  \n",
       "3  186040000  10573.679688  \n",
       "4  217390000  10606.860352  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ho\"]=(((df.High-df.Open)/df.Open)*100)\n",
    "df[\"lo\"]=(((df.Open-df.Low)/df.Open)*100)\n",
    "df[\"co\"]=(((df.Open-df.Close)/df.Open)*100)\n",
    "df[\"hl\"]=(((df.High-df.Low)/df.Low)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Open1']=(((df.Open.shift(-1)-df.Open)/df.Open)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Open2']=(((df.Open-df.Open.shift(1))/df.Open.shift(1))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label']=np.where(df['Close'].shift(-1)>df['Close'],1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rsi']=ta.momentum.rsi(df[\"Close\"], n=14, fillna=False)\n",
    "df['r']=ta.momentum.wr(df[\"High\"], df[\"Low\"], df[\"Close\"], lbp=14, fillna=False)\n",
    "df['cci']=ta.trend.cci(df[\"High\"], df[\"Low\"], df[\"Close\"], n=20, c=0.015, fillna=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rsitf']=np.where(df['rsi']>=70,2,(np.where(df['rsi']<=30,1,0)))\n",
    "df['rtf']=np.where(df['r']>=-20,2,(np.where(df['r']<=-80,1,0)))\n",
    "df['ccitf']=np.where(df['cci']<=-100,2,(np.where(df['cci']>=100,1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2663"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>ho</th>\n",
       "      <th>lo</th>\n",
       "      <th>co</th>\n",
       "      <th>hl</th>\n",
       "      <th>Open1</th>\n",
       "      <th>Open2</th>\n",
       "      <th>label</th>\n",
       "      <th>rsi</th>\n",
       "      <th>r</th>\n",
       "      <th>cci</th>\n",
       "      <th>rsitf</th>\n",
       "      <th>rtf</th>\n",
       "      <th>ccitf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>10555.009766</td>\n",
       "      <td>10423.129883</td>\n",
       "      <td>10548.509766</td>\n",
       "      <td>10428.049805</td>\n",
       "      <td>137940000</td>\n",
       "      <td>10428.049805</td>\n",
       "      <td>0.061620</td>\n",
       "      <td>1.188603</td>\n",
       "      <td>1.141962</td>\n",
       "      <td>1.265262</td>\n",
       "      <td>-1.116929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-96.269392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>10604.969727</td>\n",
       "      <td>10430.690430</td>\n",
       "      <td>10430.690430</td>\n",
       "      <td>10583.959961</td>\n",
       "      <td>179780000</td>\n",
       "      <td>10583.959961</td>\n",
       "      <td>1.670832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.469409</td>\n",
       "      <td>1.670832</td>\n",
       "      <td>1.475158</td>\n",
       "      <td>-1.116929</td>\n",
       "      <td>0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-11.553995</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>10584.559570</td>\n",
       "      <td>10522.519531</td>\n",
       "      <td>10584.559570</td>\n",
       "      <td>10572.019531</td>\n",
       "      <td>188540000</td>\n",
       "      <td>10572.019531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586137</td>\n",
       "      <td>0.118475</td>\n",
       "      <td>0.589593</td>\n",
       "      <td>-0.187441</td>\n",
       "      <td>1.475158</td>\n",
       "      <td>1</td>\n",
       "      <td>92.380758</td>\n",
       "      <td>-18.120449</td>\n",
       "      <td>68.344739</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>10594.990234</td>\n",
       "      <td>10546.549805</td>\n",
       "      <td>10564.719727</td>\n",
       "      <td>10573.679688</td>\n",
       "      <td>186040000</td>\n",
       "      <td>10573.679688</td>\n",
       "      <td>0.286524</td>\n",
       "      <td>0.171987</td>\n",
       "      <td>-0.084810</td>\n",
       "      <td>0.459301</td>\n",
       "      <td>0.060490</td>\n",
       "      <td>-0.187441</td>\n",
       "      <td>1</td>\n",
       "      <td>92.466701</td>\n",
       "      <td>-17.207471</td>\n",
       "      <td>73.886101</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>10612.370117</td>\n",
       "      <td>10505.209961</td>\n",
       "      <td>10571.110352</td>\n",
       "      <td>10606.860352</td>\n",
       "      <td>217390000</td>\n",
       "      <td>10606.860352</td>\n",
       "      <td>0.390307</td>\n",
       "      <td>0.623401</td>\n",
       "      <td>-0.338186</td>\n",
       "      <td>1.020067</td>\n",
       "      <td>0.333835</td>\n",
       "      <td>0.060490</td>\n",
       "      <td>1</td>\n",
       "      <td>93.938367</td>\n",
       "      <td>-2.911519</td>\n",
       "      <td>68.620287</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>10619.400391</td>\n",
       "      <td>10554.330078</td>\n",
       "      <td>10606.400391</td>\n",
       "      <td>10618.190430</td>\n",
       "      <td>172710000</td>\n",
       "      <td>10618.190430</td>\n",
       "      <td>0.122568</td>\n",
       "      <td>0.490933</td>\n",
       "      <td>-0.111160</td>\n",
       "      <td>0.616527</td>\n",
       "      <td>0.131139</td>\n",
       "      <td>0.333835</td>\n",
       "      <td>1</td>\n",
       "      <td>94.344639</td>\n",
       "      <td>-0.616476</td>\n",
       "      <td>94.875284</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>10676.230469</td>\n",
       "      <td>10591.589844</td>\n",
       "      <td>10620.309570</td>\n",
       "      <td>10663.990234</td>\n",
       "      <td>182050000</td>\n",
       "      <td>10663.990234</td>\n",
       "      <td>0.526547</td>\n",
       "      <td>0.270423</td>\n",
       "      <td>-0.411294</td>\n",
       "      <td>0.799131</td>\n",
       "      <td>0.400655</td>\n",
       "      <td>0.131139</td>\n",
       "      <td>0</td>\n",
       "      <td>95.622011</td>\n",
       "      <td>-4.836115</td>\n",
       "      <td>144.547664</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>10663.080078</td>\n",
       "      <td>10568.839844</td>\n",
       "      <td>10662.860352</td>\n",
       "      <td>10627.259766</td>\n",
       "      <td>256050000</td>\n",
       "      <td>10627.259766</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.881757</td>\n",
       "      <td>0.333875</td>\n",
       "      <td>0.891680</td>\n",
       "      <td>-0.326090</td>\n",
       "      <td>0.400655</td>\n",
       "      <td>1</td>\n",
       "      <td>80.013309</td>\n",
       "      <td>-19.348317</td>\n",
       "      <td>86.108167</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>10709.259766</td>\n",
       "      <td>10614.490234</td>\n",
       "      <td>10628.089844</td>\n",
       "      <td>10680.769531</td>\n",
       "      <td>202810000</td>\n",
       "      <td>10680.769531</td>\n",
       "      <td>0.763730</td>\n",
       "      <td>0.127959</td>\n",
       "      <td>-0.495665</td>\n",
       "      <td>0.892832</td>\n",
       "      <td>0.489931</td>\n",
       "      <td>-0.326090</td>\n",
       "      <td>1</td>\n",
       "      <td>84.088226</td>\n",
       "      <td>-9.957099</td>\n",
       "      <td>129.243992</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>10723.769531</td>\n",
       "      <td>10666.860352</td>\n",
       "      <td>10680.160156</td>\n",
       "      <td>10710.549805</td>\n",
       "      <td>201320000</td>\n",
       "      <td>10710.549805</td>\n",
       "      <td>0.408321</td>\n",
       "      <td>0.124528</td>\n",
       "      <td>-0.284543</td>\n",
       "      <td>0.533514</td>\n",
       "      <td>0.251214</td>\n",
       "      <td>0.489931</td>\n",
       "      <td>0</td>\n",
       "      <td>85.820864</td>\n",
       "      <td>-4.397200</td>\n",
       "      <td>137.242302</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>10709.940430</td>\n",
       "      <td>10561.059570</td>\n",
       "      <td>10706.990234</td>\n",
       "      <td>10609.650391</td>\n",
       "      <td>362930000</td>\n",
       "      <td>10609.650391</td>\n",
       "      <td>0.027554</td>\n",
       "      <td>1.362948</td>\n",
       "      <td>0.909124</td>\n",
       "      <td>1.409715</td>\n",
       "      <td>-0.921082</td>\n",
       "      <td>0.251214</td>\n",
       "      <td>1</td>\n",
       "      <td>61.418448</td>\n",
       "      <td>-37.958779</td>\n",
       "      <td>39.735258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>10729.889648</td>\n",
       "      <td>10591.969727</td>\n",
       "      <td>10608.370117</td>\n",
       "      <td>10725.429688</td>\n",
       "      <td>192150000</td>\n",
       "      <td>10725.429688</td>\n",
       "      <td>1.145506</td>\n",
       "      <td>0.154599</td>\n",
       "      <td>-1.103464</td>\n",
       "      <td>1.302118</td>\n",
       "      <td>1.049363</td>\n",
       "      <td>-0.921082</td>\n",
       "      <td>0</td>\n",
       "      <td>71.450083</td>\n",
       "      <td>-1.453894</td>\n",
       "      <td>99.086971</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010-01-20</td>\n",
       "      <td>10719.919922</td>\n",
       "      <td>10517.299805</td>\n",
       "      <td>10719.690430</td>\n",
       "      <td>10603.150391</td>\n",
       "      <td>203270000</td>\n",
       "      <td>10603.150391</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>1.888027</td>\n",
       "      <td>1.087159</td>\n",
       "      <td>1.926541</td>\n",
       "      <td>-1.080071</td>\n",
       "      <td>1.049363</td>\n",
       "      <td>0</td>\n",
       "      <td>55.142627</td>\n",
       "      <td>-41.315476</td>\n",
       "      <td>11.267518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010-01-21</td>\n",
       "      <td>10614.940430</td>\n",
       "      <td>10374.690430</td>\n",
       "      <td>10603.910156</td>\n",
       "      <td>10389.879883</td>\n",
       "      <td>304290000</td>\n",
       "      <td>10389.879883</td>\n",
       "      <td>0.104021</td>\n",
       "      <td>2.161653</td>\n",
       "      <td>2.018409</td>\n",
       "      <td>2.315732</td>\n",
       "      <td>-2.021236</td>\n",
       "      <td>-1.080071</td>\n",
       "      <td>0</td>\n",
       "      <td>38.596564</td>\n",
       "      <td>-95.723681</td>\n",
       "      <td>-159.829243</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010-01-22</td>\n",
       "      <td>10389.580078</td>\n",
       "      <td>10157.639648</td>\n",
       "      <td>10389.580078</td>\n",
       "      <td>10172.980469</td>\n",
       "      <td>323620000</td>\n",
       "      <td>10172.980469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.232433</td>\n",
       "      <td>2.084777</td>\n",
       "      <td>2.283409</td>\n",
       "      <td>-2.064381</td>\n",
       "      <td>-2.021236</td>\n",
       "      <td>1</td>\n",
       "      <td>29.049694</td>\n",
       "      <td>-97.319210</td>\n",
       "      <td>-281.771008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2010-01-25</td>\n",
       "      <td>10256.870117</td>\n",
       "      <td>10171.769531</td>\n",
       "      <td>10175.099609</td>\n",
       "      <td>10196.860352</td>\n",
       "      <td>215330000</td>\n",
       "      <td>10196.860352</td>\n",
       "      <td>0.803633</td>\n",
       "      <td>0.032728</td>\n",
       "      <td>-0.213863</td>\n",
       "      <td>0.836635</td>\n",
       "      <td>0.199015</td>\n",
       "      <td>-2.064381</td>\n",
       "      <td>0</td>\n",
       "      <td>31.071184</td>\n",
       "      <td>-93.146229</td>\n",
       "      <td>-219.685220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2010-01-26</td>\n",
       "      <td>10285.129883</td>\n",
       "      <td>10155.599609</td>\n",
       "      <td>10195.349609</td>\n",
       "      <td>10194.290039</td>\n",
       "      <td>217300000</td>\n",
       "      <td>10194.290039</td>\n",
       "      <td>0.880600</td>\n",
       "      <td>0.389884</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>1.275457</td>\n",
       "      <td>-0.010393</td>\n",
       "      <td>0.199015</td>\n",
       "      <td>1</td>\n",
       "      <td>30.968906</td>\n",
       "      <td>-93.262911</td>\n",
       "      <td>-170.342977</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2010-01-27</td>\n",
       "      <td>10255.059570</td>\n",
       "      <td>10104.360352</td>\n",
       "      <td>10194.290039</td>\n",
       "      <td>10236.160156</td>\n",
       "      <td>262170000</td>\n",
       "      <td>10236.160156</td>\n",
       "      <td>0.596113</td>\n",
       "      <td>0.882157</td>\n",
       "      <td>-0.410721</td>\n",
       "      <td>1.491428</td>\n",
       "      <td>0.418174</td>\n",
       "      <td>-0.010393</td>\n",
       "      <td>0</td>\n",
       "      <td>34.737592</td>\n",
       "      <td>-78.929875</td>\n",
       "      <td>-146.773767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2010-01-28</td>\n",
       "      <td>10258.830078</td>\n",
       "      <td>10055.080078</td>\n",
       "      <td>10236.919922</td>\n",
       "      <td>10120.459961</td>\n",
       "      <td>240050000</td>\n",
       "      <td>10120.459961</td>\n",
       "      <td>0.214031</td>\n",
       "      <td>1.776314</td>\n",
       "      <td>1.137646</td>\n",
       "      <td>2.026339</td>\n",
       "      <td>-1.122211</td>\n",
       "      <td>0.418174</td>\n",
       "      <td>0</td>\n",
       "      <td>29.882700</td>\n",
       "      <td>-90.311358</td>\n",
       "      <td>-145.682809</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>10239.339844</td>\n",
       "      <td>10043.750000</td>\n",
       "      <td>10122.040039</td>\n",
       "      <td>10067.330078</td>\n",
       "      <td>316900000</td>\n",
       "      <td>10067.330078</td>\n",
       "      <td>1.158855</td>\n",
       "      <td>0.773461</td>\n",
       "      <td>0.540503</td>\n",
       "      <td>1.947379</td>\n",
       "      <td>-0.524102</td>\n",
       "      <td>-1.122211</td>\n",
       "      <td>1</td>\n",
       "      <td>27.950887</td>\n",
       "      <td>-96.563370</td>\n",
       "      <td>-137.016720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>10190.889648</td>\n",
       "      <td>10068.910156</td>\n",
       "      <td>10068.990234</td>\n",
       "      <td>10185.530273</td>\n",
       "      <td>198430000</td>\n",
       "      <td>10185.530273</td>\n",
       "      <td>1.210642</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>-1.157415</td>\n",
       "      <td>1.211447</td>\n",
       "      <td>1.163370</td>\n",
       "      <td>-0.524102</td>\n",
       "      <td>1</td>\n",
       "      <td>37.613600</td>\n",
       "      <td>-79.336528</td>\n",
       "      <td>-106.598550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>10314.839844</td>\n",
       "      <td>10173.589844</td>\n",
       "      <td>10186.129883</td>\n",
       "      <td>10296.849609</td>\n",
       "      <td>237140000</td>\n",
       "      <td>10296.849609</td>\n",
       "      <td>1.263581</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>-1.086966</td>\n",
       "      <td>1.388399</td>\n",
       "      <td>1.036710</td>\n",
       "      <td>1.163370</td>\n",
       "      <td>0</td>\n",
       "      <td>45.083433</td>\n",
       "      <td>-63.112522</td>\n",
       "      <td>-59.959082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2010-02-03</td>\n",
       "      <td>10307.200195</td>\n",
       "      <td>10231.929688</td>\n",
       "      <td>10291.730469</td>\n",
       "      <td>10270.549805</td>\n",
       "      <td>198940000</td>\n",
       "      <td>10270.549805</td>\n",
       "      <td>0.150312</td>\n",
       "      <td>0.581057</td>\n",
       "      <td>0.205803</td>\n",
       "      <td>0.735643</td>\n",
       "      <td>-0.180828</td>\n",
       "      <td>1.036710</td>\n",
       "      <td>0</td>\n",
       "      <td>43.750612</td>\n",
       "      <td>-66.945533</td>\n",
       "      <td>-51.374031</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2010-02-04</td>\n",
       "      <td>10273.120117</td>\n",
       "      <td>9998.030273</td>\n",
       "      <td>10273.120117</td>\n",
       "      <td>10002.179688</td>\n",
       "      <td>304240000</td>\n",
       "      <td>10002.179688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.677763</td>\n",
       "      <td>2.637372</td>\n",
       "      <td>2.751440</td>\n",
       "      <td>-2.622667</td>\n",
       "      <td>-0.180828</td>\n",
       "      <td>1</td>\n",
       "      <td>33.022357</td>\n",
       "      <td>-99.433031</td>\n",
       "      <td>-97.101466</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>10031.959961</td>\n",
       "      <td>9835.089844</td>\n",
       "      <td>10003.690430</td>\n",
       "      <td>10012.230469</td>\n",
       "      <td>308320000</td>\n",
       "      <td>10012.230469</td>\n",
       "      <td>0.282591</td>\n",
       "      <td>1.685384</td>\n",
       "      <td>-0.085369</td>\n",
       "      <td>2.001711</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>-2.622667</td>\n",
       "      <td>0</td>\n",
       "      <td>33.678277</td>\n",
       "      <td>-80.203323</td>\n",
       "      <td>-122.298290</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2010-02-08</td>\n",
       "      <td>10028.559570</td>\n",
       "      <td>9904.089844</td>\n",
       "      <td>10005.429688</td>\n",
       "      <td>9908.389648</td>\n",
       "      <td>216270000</td>\n",
       "      <td>9908.389648</td>\n",
       "      <td>0.231173</td>\n",
       "      <td>1.012848</td>\n",
       "      <td>0.969874</td>\n",
       "      <td>1.256751</td>\n",
       "      <td>-0.950978</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>1</td>\n",
       "      <td>30.369195</td>\n",
       "      <td>-91.715946</td>\n",
       "      <td>-114.620310</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>10139.429688</td>\n",
       "      <td>9910.059570</td>\n",
       "      <td>9910.280273</td>\n",
       "      <td>10058.639648</td>\n",
       "      <td>236210000</td>\n",
       "      <td>10058.639648</td>\n",
       "      <td>2.312239</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>-1.497025</td>\n",
       "      <td>2.314518</td>\n",
       "      <td>1.464940</td>\n",
       "      <td>-0.950978</td>\n",
       "      <td>0</td>\n",
       "      <td>39.614503</td>\n",
       "      <td>-71.334278</td>\n",
       "      <td>-83.133270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>10085.540039</td>\n",
       "      <td>9962.959961</td>\n",
       "      <td>10055.459961</td>\n",
       "      <td>10038.379883</td>\n",
       "      <td>178600000</td>\n",
       "      <td>10038.379883</td>\n",
       "      <td>0.299142</td>\n",
       "      <td>0.919898</td>\n",
       "      <td>0.169859</td>\n",
       "      <td>1.230358</td>\n",
       "      <td>-0.175132</td>\n",
       "      <td>1.464940</td>\n",
       "      <td>1</td>\n",
       "      <td>38.865152</td>\n",
       "      <td>-63.337490</td>\n",
       "      <td>-81.208906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2010-02-11</td>\n",
       "      <td>10161.570312</td>\n",
       "      <td>9976.709961</td>\n",
       "      <td>10037.849609</td>\n",
       "      <td>10144.190430</td>\n",
       "      <td>194470000</td>\n",
       "      <td>10144.190430</td>\n",
       "      <td>1.232542</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>-1.059398</td>\n",
       "      <td>1.852919</td>\n",
       "      <td>0.990061</td>\n",
       "      <td>-0.175132</td>\n",
       "      <td>0</td>\n",
       "      <td>44.743966</td>\n",
       "      <td>-35.570488</td>\n",
       "      <td>-56.874785</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>10137.389648</td>\n",
       "      <td>9983.820312</td>\n",
       "      <td>10137.230469</td>\n",
       "      <td>10099.139648</td>\n",
       "      <td>296510000</td>\n",
       "      <td>10099.139648</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>1.513334</td>\n",
       "      <td>0.375752</td>\n",
       "      <td>1.538182</td>\n",
       "      <td>-0.359279</td>\n",
       "      <td>0.990061</td>\n",
       "      <td>1</td>\n",
       "      <td>42.854432</td>\n",
       "      <td>-44.960958</td>\n",
       "      <td>-60.979892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>26154.199219</td>\n",
       "      <td>25848.529297</td>\n",
       "      <td>26016.449219</td>\n",
       "      <td>26080.099609</td>\n",
       "      <td>328390000</td>\n",
       "      <td>26080.099609</td>\n",
       "      <td>0.529473</td>\n",
       "      <td>0.645438</td>\n",
       "      <td>-0.244654</td>\n",
       "      <td>1.182543</td>\n",
       "      <td>0.755869</td>\n",
       "      <td>-1.192800</td>\n",
       "      <td>0</td>\n",
       "      <td>55.170071</td>\n",
       "      <td>-54.807972</td>\n",
       "      <td>14.485357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>26451.439453</td>\n",
       "      <td>25759.660156</td>\n",
       "      <td>26213.099609</td>\n",
       "      <td>25871.460938</td>\n",
       "      <td>669390000</td>\n",
       "      <td>25871.460938</td>\n",
       "      <td>0.909239</td>\n",
       "      <td>1.729820</td>\n",
       "      <td>1.303313</td>\n",
       "      <td>2.685514</td>\n",
       "      <td>-1.327655</td>\n",
       "      <td>0.755869</td>\n",
       "      <td>1</td>\n",
       "      <td>53.039260</td>\n",
       "      <td>-62.430782</td>\n",
       "      <td>7.920634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>26059.810547</td>\n",
       "      <td>25667.679688</td>\n",
       "      <td>25865.080078</td>\n",
       "      <td>26024.960938</td>\n",
       "      <td>351780000</td>\n",
       "      <td>26024.960938</td>\n",
       "      <td>0.752870</td>\n",
       "      <td>0.763193</td>\n",
       "      <td>-0.618134</td>\n",
       "      <td>1.527722</td>\n",
       "      <td>1.137868</td>\n",
       "      <td>-1.327655</td>\n",
       "      <td>1</td>\n",
       "      <td>54.433649</td>\n",
       "      <td>-56.822515</td>\n",
       "      <td>-13.156981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>26314.970703</td>\n",
       "      <td>26105.970703</td>\n",
       "      <td>26159.390625</td>\n",
       "      <td>26156.099609</td>\n",
       "      <td>389980000</td>\n",
       "      <td>26156.099609</td>\n",
       "      <td>0.594739</td>\n",
       "      <td>0.204209</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>0.800583</td>\n",
       "      <td>-0.636214</td>\n",
       "      <td>1.137868</td>\n",
       "      <td>0</td>\n",
       "      <td>55.645349</td>\n",
       "      <td>-52.031241</td>\n",
       "      <td>13.394462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>2020-06-24</td>\n",
       "      <td>25992.960938</td>\n",
       "      <td>25296.730469</td>\n",
       "      <td>25992.960938</td>\n",
       "      <td>25445.939453</td>\n",
       "      <td>450120000</td>\n",
       "      <td>25445.939453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.678535</td>\n",
       "      <td>2.104499</td>\n",
       "      <td>2.752255</td>\n",
       "      <td>-2.415039</td>\n",
       "      <td>-0.636214</td>\n",
       "      <td>1</td>\n",
       "      <td>48.174375</td>\n",
       "      <td>-77.977607</td>\n",
       "      <td>-67.904419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>25769.609375</td>\n",
       "      <td>25209.789062</td>\n",
       "      <td>25365.220703</td>\n",
       "      <td>25745.599609</td>\n",
       "      <td>384560000</td>\n",
       "      <td>25745.599609</td>\n",
       "      <td>1.594264</td>\n",
       "      <td>0.612775</td>\n",
       "      <td>-1.499608</td>\n",
       "      <td>2.220647</td>\n",
       "      <td>1.089952</td>\n",
       "      <td>-2.415039</td>\n",
       "      <td>0</td>\n",
       "      <td>51.154473</td>\n",
       "      <td>-67.029243</td>\n",
       "      <td>-69.238676</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>25641.689453</td>\n",
       "      <td>24971.029297</td>\n",
       "      <td>25641.689453</td>\n",
       "      <td>25015.550781</td>\n",
       "      <td>640860000</td>\n",
       "      <td>25015.550781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.615507</td>\n",
       "      <td>2.441878</td>\n",
       "      <td>2.685753</td>\n",
       "      <td>-1.907988</td>\n",
       "      <td>1.089952</td>\n",
       "      <td>1</td>\n",
       "      <td>44.448649</td>\n",
       "      <td>-93.381008</td>\n",
       "      <td>-115.774855</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>25601.150391</td>\n",
       "      <td>25096.160156</td>\n",
       "      <td>25152.449219</td>\n",
       "      <td>25595.800781</td>\n",
       "      <td>378070000</td>\n",
       "      <td>25595.800781</td>\n",
       "      <td>1.783926</td>\n",
       "      <td>0.223792</td>\n",
       "      <td>-1.762658</td>\n",
       "      <td>2.012221</td>\n",
       "      <td>1.431194</td>\n",
       "      <td>-1.907988</td>\n",
       "      <td>1</td>\n",
       "      <td>50.053006</td>\n",
       "      <td>-70.039458</td>\n",
       "      <td>-87.297460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>25905.380859</td>\n",
       "      <td>25475.140625</td>\n",
       "      <td>25512.429688</td>\n",
       "      <td>25812.880859</td>\n",
       "      <td>410780000</td>\n",
       "      <td>25812.880859</td>\n",
       "      <td>1.540234</td>\n",
       "      <td>0.146160</td>\n",
       "      <td>-1.177666</td>\n",
       "      <td>1.688863</td>\n",
       "      <td>1.438323</td>\n",
       "      <td>1.431194</td>\n",
       "      <td>0</td>\n",
       "      <td>52.003870</td>\n",
       "      <td>-45.147983</td>\n",
       "      <td>-48.729201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>26019.310547</td>\n",
       "      <td>25713.609375</td>\n",
       "      <td>25879.380859</td>\n",
       "      <td>25734.970703</td>\n",
       "      <td>373180000</td>\n",
       "      <td>25734.970703</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.640554</td>\n",
       "      <td>0.558012</td>\n",
       "      <td>1.188869</td>\n",
       "      <td>0.220517</td>\n",
       "      <td>1.438323</td>\n",
       "      <td>1</td>\n",
       "      <td>51.230469</td>\n",
       "      <td>-49.555041</td>\n",
       "      <td>-33.941951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>26204.410156</td>\n",
       "      <td>25778.119141</td>\n",
       "      <td>25936.449219</td>\n",
       "      <td>25827.359375</td>\n",
       "      <td>349130000</td>\n",
       "      <td>25827.359375</td>\n",
       "      <td>1.033144</td>\n",
       "      <td>0.610454</td>\n",
       "      <td>0.420604</td>\n",
       "      <td>1.653693</td>\n",
       "      <td>0.229911</td>\n",
       "      <td>0.220517</td>\n",
       "      <td>1</td>\n",
       "      <td>52.139453</td>\n",
       "      <td>-44.328993</td>\n",
       "      <td>-17.320503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>26297.529297</td>\n",
       "      <td>25996.080078</td>\n",
       "      <td>25996.080078</td>\n",
       "      <td>26287.029297</td>\n",
       "      <td>340690000</td>\n",
       "      <td>26287.029297</td>\n",
       "      <td>1.159595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.119204</td>\n",
       "      <td>1.159595</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>0.229911</td>\n",
       "      <td>0</td>\n",
       "      <td>56.485127</td>\n",
       "      <td>-19.756098</td>\n",
       "      <td>25.121030</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>26174.929688</td>\n",
       "      <td>25866.580078</td>\n",
       "      <td>26172.009766</td>\n",
       "      <td>25890.179688</td>\n",
       "      <td>346820000</td>\n",
       "      <td>25890.179688</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>1.167009</td>\n",
       "      <td>1.076838</td>\n",
       "      <td>1.192077</td>\n",
       "      <td>-0.848040</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>1</td>\n",
       "      <td>52.087881</td>\n",
       "      <td>-37.912450</td>\n",
       "      <td>5.015310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>26109.490234</td>\n",
       "      <td>25816.250000</td>\n",
       "      <td>25950.060547</td>\n",
       "      <td>26067.279297</td>\n",
       "      <td>337300000</td>\n",
       "      <td>26067.279297</td>\n",
       "      <td>0.614371</td>\n",
       "      <td>0.515646</td>\n",
       "      <td>-0.451709</td>\n",
       "      <td>1.135875</td>\n",
       "      <td>0.558224</td>\n",
       "      <td>-0.848040</td>\n",
       "      <td>0</td>\n",
       "      <td>53.815773</td>\n",
       "      <td>-25.949576</td>\n",
       "      <td>24.544878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>26103.279297</td>\n",
       "      <td>25523.509766</td>\n",
       "      <td>26094.919922</td>\n",
       "      <td>25706.089844</td>\n",
       "      <td>387610000</td>\n",
       "      <td>25706.089844</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>2.189737</td>\n",
       "      <td>1.490060</td>\n",
       "      <td>2.271512</td>\n",
       "      <td>-1.550380</td>\n",
       "      <td>0.558224</td>\n",
       "      <td>1</td>\n",
       "      <td>49.865951</td>\n",
       "      <td>-50.347507</td>\n",
       "      <td>-10.954631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648</th>\n",
       "      <td>2020-07-10</td>\n",
       "      <td>26101.320312</td>\n",
       "      <td>25637.500000</td>\n",
       "      <td>25690.349609</td>\n",
       "      <td>26075.300781</td>\n",
       "      <td>338170000</td>\n",
       "      <td>26075.300781</td>\n",
       "      <td>1.599708</td>\n",
       "      <td>0.205718</td>\n",
       "      <td>-1.498427</td>\n",
       "      <td>1.809148</td>\n",
       "      <td>2.081407</td>\n",
       "      <td>-1.550380</td>\n",
       "      <td>1</td>\n",
       "      <td>53.613791</td>\n",
       "      <td>-17.833361</td>\n",
       "      <td>27.089955</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2649</th>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>26639.089844</td>\n",
       "      <td>26044.230469</td>\n",
       "      <td>26225.070312</td>\n",
       "      <td>26085.800781</td>\n",
       "      <td>425320000</td>\n",
       "      <td>26085.800781</td>\n",
       "      <td>1.578717</td>\n",
       "      <td>0.689569</td>\n",
       "      <td>0.531055</td>\n",
       "      <td>2.284035</td>\n",
       "      <td>-0.689799</td>\n",
       "      <td>2.081407</td>\n",
       "      <td>1</td>\n",
       "      <td>53.719751</td>\n",
       "      <td>-33.169603</td>\n",
       "      <td>106.312115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>26690.519531</td>\n",
       "      <td>25994.980469</td>\n",
       "      <td>26044.169922</td>\n",
       "      <td>26642.589844</td>\n",
       "      <td>401640000</td>\n",
       "      <td>26642.589844</td>\n",
       "      <td>2.481744</td>\n",
       "      <td>0.188869</td>\n",
       "      <td>-2.297712</td>\n",
       "      <td>2.675667</td>\n",
       "      <td>3.707704</td>\n",
       "      <td>-0.689799</td>\n",
       "      <td>1</td>\n",
       "      <td>59.060293</td>\n",
       "      <td>-2.787436</td>\n",
       "      <td>147.748181</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>2020-07-15</td>\n",
       "      <td>27071.330078</td>\n",
       "      <td>26692.480469</td>\n",
       "      <td>27009.810547</td>\n",
       "      <td>26870.099609</td>\n",
       "      <td>384900000</td>\n",
       "      <td>26870.099609</td>\n",
       "      <td>0.227767</td>\n",
       "      <td>1.174870</td>\n",
       "      <td>0.517260</td>\n",
       "      <td>1.419312</td>\n",
       "      <td>-0.974610</td>\n",
       "      <td>3.707704</td>\n",
       "      <td>0</td>\n",
       "      <td>61.038706</td>\n",
       "      <td>-9.581031</td>\n",
       "      <td>233.368585</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>26879.160156</td>\n",
       "      <td>26590.009766</td>\n",
       "      <td>26746.570312</td>\n",
       "      <td>26734.710938</td>\n",
       "      <td>287330000</td>\n",
       "      <td>26734.710938</td>\n",
       "      <td>0.495727</td>\n",
       "      <td>0.585348</td>\n",
       "      <td>0.044340</td>\n",
       "      <td>1.087440</td>\n",
       "      <td>0.104869</td>\n",
       "      <td>-0.974610</td>\n",
       "      <td>0</td>\n",
       "      <td>59.205131</td>\n",
       "      <td>-16.027187</td>\n",
       "      <td>172.361282</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>26808.429688</td>\n",
       "      <td>26619.880859</td>\n",
       "      <td>26774.619141</td>\n",
       "      <td>26671.949219</td>\n",
       "      <td>296460000</td>\n",
       "      <td>26671.949219</td>\n",
       "      <td>0.126278</td>\n",
       "      <td>0.577929</td>\n",
       "      <td>0.383460</td>\n",
       "      <td>0.708301</td>\n",
       "      <td>-0.427009</td>\n",
       "      <td>0.104869</td>\n",
       "      <td>1</td>\n",
       "      <td>58.330379</td>\n",
       "      <td>-20.220076</td>\n",
       "      <td>138.302156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>2020-07-20</td>\n",
       "      <td>26765.019531</td>\n",
       "      <td>26504.199219</td>\n",
       "      <td>26660.289062</td>\n",
       "      <td>26680.869141</td>\n",
       "      <td>309390000</td>\n",
       "      <td>26680.869141</td>\n",
       "      <td>0.392833</td>\n",
       "      <td>0.585477</td>\n",
       "      <td>-0.077194</td>\n",
       "      <td>0.984072</td>\n",
       "      <td>0.648348</td>\n",
       "      <td>-0.427009</td>\n",
       "      <td>1</td>\n",
       "      <td>58.424398</td>\n",
       "      <td>-24.462067</td>\n",
       "      <td>109.492453</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2655</th>\n",
       "      <td>2020-07-21</td>\n",
       "      <td>27025.380859</td>\n",
       "      <td>26766.220703</td>\n",
       "      <td>26833.140625</td>\n",
       "      <td>26840.400391</td>\n",
       "      <td>364930000</td>\n",
       "      <td>26840.400391</td>\n",
       "      <td>0.716428</td>\n",
       "      <td>0.249393</td>\n",
       "      <td>-0.027055</td>\n",
       "      <td>0.968236</td>\n",
       "      <td>-0.031976</td>\n",
       "      <td>0.648348</td>\n",
       "      <td>1</td>\n",
       "      <td>60.155923</td>\n",
       "      <td>-14.919670</td>\n",
       "      <td>128.145971</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2656</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>27035.240234</td>\n",
       "      <td>26794.189453</td>\n",
       "      <td>26824.560547</td>\n",
       "      <td>27005.839844</td>\n",
       "      <td>404340000</td>\n",
       "      <td>27005.839844</td>\n",
       "      <td>0.785398</td>\n",
       "      <td>0.113221</td>\n",
       "      <td>-0.675796</td>\n",
       "      <td>0.899638</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>-0.031976</td>\n",
       "      <td>0</td>\n",
       "      <td>61.926798</td>\n",
       "      <td>-4.231126</td>\n",
       "      <td>120.792231</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>26973.849609</td>\n",
       "      <td>26560.039062</td>\n",
       "      <td>26955.970703</td>\n",
       "      <td>26652.330078</td>\n",
       "      <td>419800000</td>\n",
       "      <td>26652.330078</td>\n",
       "      <td>0.066326</td>\n",
       "      <td>1.468809</td>\n",
       "      <td>1.126432</td>\n",
       "      <td>1.558019</td>\n",
       "      <td>-1.567595</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>0</td>\n",
       "      <td>56.180878</td>\n",
       "      <td>-27.070326</td>\n",
       "      <td>79.702496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>26625.699219</td>\n",
       "      <td>26402.859375</td>\n",
       "      <td>26533.410156</td>\n",
       "      <td>26469.890625</td>\n",
       "      <td>494170000</td>\n",
       "      <td>26469.890625</td>\n",
       "      <td>0.347822</td>\n",
       "      <td>0.492024</td>\n",
       "      <td>0.239395</td>\n",
       "      <td>0.843999</td>\n",
       "      <td>-0.323141</td>\n",
       "      <td>-1.567595</td>\n",
       "      <td>1</td>\n",
       "      <td>53.425799</td>\n",
       "      <td>-38.857188</td>\n",
       "      <td>40.335622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>26625.460938</td>\n",
       "      <td>26426.919922</td>\n",
       "      <td>26447.669922</td>\n",
       "      <td>26584.769531</td>\n",
       "      <td>400930000</td>\n",
       "      <td>26584.769531</td>\n",
       "      <td>0.672237</td>\n",
       "      <td>0.078457</td>\n",
       "      <td>-0.518381</td>\n",
       "      <td>0.751283</td>\n",
       "      <td>0.309212</td>\n",
       "      <td>-0.323141</td>\n",
       "      <td>0</td>\n",
       "      <td>54.924758</td>\n",
       "      <td>-31.435209</td>\n",
       "      <td>40.728236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>26556.839844</td>\n",
       "      <td>26361.710938</td>\n",
       "      <td>26529.449219</td>\n",
       "      <td>26379.279297</td>\n",
       "      <td>361090000</td>\n",
       "      <td>26379.279297</td>\n",
       "      <td>0.103246</td>\n",
       "      <td>0.632272</td>\n",
       "      <td>0.566050</td>\n",
       "      <td>0.740198</td>\n",
       "      <td>-0.531522</td>\n",
       "      <td>0.309212</td>\n",
       "      <td>1</td>\n",
       "      <td>51.718310</td>\n",
       "      <td>-44.711313</td>\n",
       "      <td>14.907147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>26602.449219</td>\n",
       "      <td>26375.390625</td>\n",
       "      <td>26388.439453</td>\n",
       "      <td>26539.570312</td>\n",
       "      <td>347580000</td>\n",
       "      <td>26539.570312</td>\n",
       "      <td>0.810998</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>-0.572716</td>\n",
       "      <td>0.860873</td>\n",
       "      <td>-0.079654</td>\n",
       "      <td>-0.531522</td>\n",
       "      <td>0</td>\n",
       "      <td>53.975399</td>\n",
       "      <td>-37.086666</td>\n",
       "      <td>23.444314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>26374.929688</td>\n",
       "      <td>25992.279297</td>\n",
       "      <td>26367.419922</td>\n",
       "      <td>26313.650391</td>\n",
       "      <td>351540000</td>\n",
       "      <td>26313.650391</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>1.422743</td>\n",
       "      <td>0.203924</td>\n",
       "      <td>1.472169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.079654</td>\n",
       "      <td>0</td>\n",
       "      <td>50.399213</td>\n",
       "      <td>-70.217241</td>\n",
       "      <td>-41.256430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2663 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          High           Low          Open         Close  \\\n",
       "0     2009-12-31  10555.009766  10423.129883  10548.509766  10428.049805   \n",
       "1     2010-01-04  10604.969727  10430.690430  10430.690430  10583.959961   \n",
       "2     2010-01-05  10584.559570  10522.519531  10584.559570  10572.019531   \n",
       "3     2010-01-06  10594.990234  10546.549805  10564.719727  10573.679688   \n",
       "4     2010-01-07  10612.370117  10505.209961  10571.110352  10606.860352   \n",
       "5     2010-01-08  10619.400391  10554.330078  10606.400391  10618.190430   \n",
       "6     2010-01-11  10676.230469  10591.589844  10620.309570  10663.990234   \n",
       "7     2010-01-12  10663.080078  10568.839844  10662.860352  10627.259766   \n",
       "8     2010-01-13  10709.259766  10614.490234  10628.089844  10680.769531   \n",
       "9     2010-01-14  10723.769531  10666.860352  10680.160156  10710.549805   \n",
       "10    2010-01-15  10709.940430  10561.059570  10706.990234  10609.650391   \n",
       "11    2010-01-19  10729.889648  10591.969727  10608.370117  10725.429688   \n",
       "12    2010-01-20  10719.919922  10517.299805  10719.690430  10603.150391   \n",
       "13    2010-01-21  10614.940430  10374.690430  10603.910156  10389.879883   \n",
       "14    2010-01-22  10389.580078  10157.639648  10389.580078  10172.980469   \n",
       "15    2010-01-25  10256.870117  10171.769531  10175.099609  10196.860352   \n",
       "16    2010-01-26  10285.129883  10155.599609  10195.349609  10194.290039   \n",
       "17    2010-01-27  10255.059570  10104.360352  10194.290039  10236.160156   \n",
       "18    2010-01-28  10258.830078  10055.080078  10236.919922  10120.459961   \n",
       "19    2010-01-29  10239.339844  10043.750000  10122.040039  10067.330078   \n",
       "20    2010-02-01  10190.889648  10068.910156  10068.990234  10185.530273   \n",
       "21    2010-02-02  10314.839844  10173.589844  10186.129883  10296.849609   \n",
       "22    2010-02-03  10307.200195  10231.929688  10291.730469  10270.549805   \n",
       "23    2010-02-04  10273.120117   9998.030273  10273.120117  10002.179688   \n",
       "24    2010-02-05  10031.959961   9835.089844  10003.690430  10012.230469   \n",
       "25    2010-02-08  10028.559570   9904.089844  10005.429688   9908.389648   \n",
       "26    2010-02-09  10139.429688   9910.059570   9910.280273  10058.639648   \n",
       "27    2010-02-10  10085.540039   9962.959961  10055.459961  10038.379883   \n",
       "28    2010-02-11  10161.570312   9976.709961  10037.849609  10144.190430   \n",
       "29    2010-02-12  10137.389648   9983.820312  10137.230469  10099.139648   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "2633  2020-06-18  26154.199219  25848.529297  26016.449219  26080.099609   \n",
       "2634  2020-06-19  26451.439453  25759.660156  26213.099609  25871.460938   \n",
       "2635  2020-06-22  26059.810547  25667.679688  25865.080078  26024.960938   \n",
       "2636  2020-06-23  26314.970703  26105.970703  26159.390625  26156.099609   \n",
       "2637  2020-06-24  25992.960938  25296.730469  25992.960938  25445.939453   \n",
       "2638  2020-06-25  25769.609375  25209.789062  25365.220703  25745.599609   \n",
       "2639  2020-06-26  25641.689453  24971.029297  25641.689453  25015.550781   \n",
       "2640  2020-06-29  25601.150391  25096.160156  25152.449219  25595.800781   \n",
       "2641  2020-06-30  25905.380859  25475.140625  25512.429688  25812.880859   \n",
       "2642  2020-07-01  26019.310547  25713.609375  25879.380859  25734.970703   \n",
       "2643  2020-07-02  26204.410156  25778.119141  25936.449219  25827.359375   \n",
       "2644  2020-07-06  26297.529297  25996.080078  25996.080078  26287.029297   \n",
       "2645  2020-07-07  26174.929688  25866.580078  26172.009766  25890.179688   \n",
       "2646  2020-07-08  26109.490234  25816.250000  25950.060547  26067.279297   \n",
       "2647  2020-07-09  26103.279297  25523.509766  26094.919922  25706.089844   \n",
       "2648  2020-07-10  26101.320312  25637.500000  25690.349609  26075.300781   \n",
       "2649  2020-07-13  26639.089844  26044.230469  26225.070312  26085.800781   \n",
       "2650  2020-07-14  26690.519531  25994.980469  26044.169922  26642.589844   \n",
       "2651  2020-07-15  27071.330078  26692.480469  27009.810547  26870.099609   \n",
       "2652  2020-07-16  26879.160156  26590.009766  26746.570312  26734.710938   \n",
       "2653  2020-07-17  26808.429688  26619.880859  26774.619141  26671.949219   \n",
       "2654  2020-07-20  26765.019531  26504.199219  26660.289062  26680.869141   \n",
       "2655  2020-07-21  27025.380859  26766.220703  26833.140625  26840.400391   \n",
       "2656  2020-07-22  27035.240234  26794.189453  26824.560547  27005.839844   \n",
       "2657  2020-07-23  26973.849609  26560.039062  26955.970703  26652.330078   \n",
       "2658  2020-07-24  26625.699219  26402.859375  26533.410156  26469.890625   \n",
       "2659  2020-07-27  26625.460938  26426.919922  26447.669922  26584.769531   \n",
       "2660  2020-07-28  26556.839844  26361.710938  26529.449219  26379.279297   \n",
       "2661  2020-07-29  26602.449219  26375.390625  26388.439453  26539.570312   \n",
       "2662  2020-07-30  26374.929688  25992.279297  26367.419922  26313.650391   \n",
       "\n",
       "         Volume     Adj Close        ho        lo        co        hl  \\\n",
       "0     137940000  10428.049805  0.061620  1.188603  1.141962  1.265262   \n",
       "1     179780000  10583.959961  1.670832  0.000000 -1.469409  1.670832   \n",
       "2     188540000  10572.019531  0.000000  0.586137  0.118475  0.589593   \n",
       "3     186040000  10573.679688  0.286524  0.171987 -0.084810  0.459301   \n",
       "4     217390000  10606.860352  0.390307  0.623401 -0.338186  1.020067   \n",
       "5     172710000  10618.190430  0.122568  0.490933 -0.111160  0.616527   \n",
       "6     182050000  10663.990234  0.526547  0.270423 -0.411294  0.799131   \n",
       "7     256050000  10627.259766  0.002061  0.881757  0.333875  0.891680   \n",
       "8     202810000  10680.769531  0.763730  0.127959 -0.495665  0.892832   \n",
       "9     201320000  10710.549805  0.408321  0.124528 -0.284543  0.533514   \n",
       "10    362930000  10609.650391  0.027554  1.362948  0.909124  1.409715   \n",
       "11    192150000  10725.429688  1.145506  0.154599 -1.103464  1.302118   \n",
       "12    203270000  10603.150391  0.002141  1.888027  1.087159  1.926541   \n",
       "13    304290000  10389.879883  0.104021  2.161653  2.018409  2.315732   \n",
       "14    323620000  10172.980469  0.000000  2.232433  2.084777  2.283409   \n",
       "15    215330000  10196.860352  0.803633  0.032728 -0.213863  0.836635   \n",
       "16    217300000  10194.290039  0.880600  0.389884  0.010393  1.275457   \n",
       "17    262170000  10236.160156  0.596113  0.882157 -0.410721  1.491428   \n",
       "18    240050000  10120.459961  0.214031  1.776314  1.137646  2.026339   \n",
       "19    316900000  10067.330078  1.158855  0.773461  0.540503  1.947379   \n",
       "20    198430000  10185.530273  1.210642  0.000795 -1.157415  1.211447   \n",
       "21    237140000  10296.849609  1.263581  0.123109 -1.086966  1.388399   \n",
       "22    198940000  10270.549805  0.150312  0.581057  0.205803  0.735643   \n",
       "23    304240000  10002.179688  0.000000  2.677763  2.637372  2.751440   \n",
       "24    308320000  10012.230469  0.282591  1.685384 -0.085369  2.001711   \n",
       "25    216270000   9908.389648  0.231173  1.012848  0.969874  1.256751   \n",
       "26    236210000  10058.639648  2.312239  0.002227 -1.497025  2.314518   \n",
       "27    178600000  10038.379883  0.299142  0.919898  0.169859  1.230358   \n",
       "28    194470000  10144.190430  1.232542  0.609091 -1.059398  1.852919   \n",
       "29    296510000  10099.139648  0.001570  1.513334  0.375752  1.538182   \n",
       "...         ...           ...       ...       ...       ...       ...   \n",
       "2633  328390000  26080.099609  0.529473  0.645438 -0.244654  1.182543   \n",
       "2634  669390000  25871.460938  0.909239  1.729820  1.303313  2.685514   \n",
       "2635  351780000  26024.960938  0.752870  0.763193 -0.618134  1.527722   \n",
       "2636  389980000  26156.099609  0.594739  0.204209  0.012581  0.800583   \n",
       "2637  450120000  25445.939453  0.000000  2.678535  2.104499  2.752255   \n",
       "2638  384560000  25745.599609  1.594264  0.612775 -1.499608  2.220647   \n",
       "2639  640860000  25015.550781  0.000000  2.615507  2.441878  2.685753   \n",
       "2640  378070000  25595.800781  1.783926  0.223792 -1.762658  2.012221   \n",
       "2641  410780000  25812.880859  1.540234  0.146160 -1.177666  1.688863   \n",
       "2642  373180000  25734.970703  0.540700  0.640554  0.558012  1.188869   \n",
       "2643  349130000  25827.359375  1.033144  0.610454  0.420604  1.653693   \n",
       "2644  340690000  26287.029297  1.159595  0.000000 -1.119204  1.159595   \n",
       "2645  346820000  25890.179688  0.011157  1.167009  1.076838  1.192077   \n",
       "2646  337300000  26067.279297  0.614371  0.515646 -0.451709  1.135875   \n",
       "2647  387610000  25706.089844  0.032034  2.189737  1.490060  2.271512   \n",
       "2648  338170000  26075.300781  1.599708  0.205718 -1.498427  1.809148   \n",
       "2649  425320000  26085.800781  1.578717  0.689569  0.531055  2.284035   \n",
       "2650  401640000  26642.589844  2.481744  0.188869 -2.297712  2.675667   \n",
       "2651  384900000  26870.099609  0.227767  1.174870  0.517260  1.419312   \n",
       "2652  287330000  26734.710938  0.495727  0.585348  0.044340  1.087440   \n",
       "2653  296460000  26671.949219  0.126278  0.577929  0.383460  0.708301   \n",
       "2654  309390000  26680.869141  0.392833  0.585477 -0.077194  0.984072   \n",
       "2655  364930000  26840.400391  0.716428  0.249393 -0.027055  0.968236   \n",
       "2656  404340000  27005.839844  0.785398  0.113221 -0.675796  0.899638   \n",
       "2657  419800000  26652.330078  0.066326  1.468809  1.126432  1.558019   \n",
       "2658  494170000  26469.890625  0.347822  0.492024  0.239395  0.843999   \n",
       "2659  400930000  26584.769531  0.672237  0.078457 -0.518381  0.751283   \n",
       "2660  361090000  26379.279297  0.103246  0.632272  0.566050  0.740198   \n",
       "2661  347580000  26539.570312  0.810998  0.049449 -0.572716  0.860873   \n",
       "2662  351540000  26313.650391  0.028481  1.422743  0.203924  1.472169   \n",
       "\n",
       "         Open1     Open2  label         rsi          r         cci  rsitf  \\\n",
       "0    -1.116929       NaN      1  100.000000 -96.269392         NaN      2   \n",
       "1     1.475158 -1.116929      0  100.000000 -11.553995   66.666667      2   \n",
       "2    -0.187441  1.475158      1   92.380758 -18.120449   68.344739      2   \n",
       "3     0.060490 -0.187441      1   92.466701 -17.207471   73.886101      2   \n",
       "4     0.333835  0.060490      1   93.938367  -2.911519   68.620287      2   \n",
       "5     0.131139  0.333835      1   94.344639  -0.616476   94.875284      2   \n",
       "6     0.400655  0.131139      0   95.622011  -4.836115  144.547664      2   \n",
       "7    -0.326090  0.400655      1   80.013309 -19.348317   86.108167      2   \n",
       "8     0.489931 -0.326090      1   84.088226  -9.957099  129.243992      2   \n",
       "9     0.251214  0.489931      0   85.820864  -4.397200  137.242302      2   \n",
       "10   -0.921082  0.251214      1   61.418448 -37.958779   39.735258      0   \n",
       "11    1.049363 -0.921082      0   71.450083  -1.453894   99.086971      2   \n",
       "12   -1.080071  1.049363      0   55.142627 -41.315476   11.267518      0   \n",
       "13   -2.021236 -1.080071      0   38.596564 -95.723681 -159.829243      0   \n",
       "14   -2.064381 -2.021236      1   29.049694 -97.319210 -281.771008      1   \n",
       "15    0.199015 -2.064381      0   31.071184 -93.146229 -219.685220      0   \n",
       "16   -0.010393  0.199015      1   30.968906 -93.262911 -170.342977      0   \n",
       "17    0.418174 -0.010393      0   34.737592 -78.929875 -146.773767      0   \n",
       "18   -1.122211  0.418174      0   29.882700 -90.311358 -145.682809      1   \n",
       "19   -0.524102 -1.122211      1   27.950887 -96.563370 -137.016720      1   \n",
       "20    1.163370 -0.524102      1   37.613600 -79.336528 -106.598550      0   \n",
       "21    1.036710  1.163370      0   45.083433 -63.112522  -59.959082      0   \n",
       "22   -0.180828  1.036710      0   43.750612 -66.945533  -51.374031      0   \n",
       "23   -2.622667 -0.180828      1   33.022357 -99.433031  -97.101466      0   \n",
       "24    0.017386 -2.622667      0   33.678277 -80.203323 -122.298290      0   \n",
       "25   -0.950978  0.017386      1   30.369195 -91.715946 -114.620310      0   \n",
       "26    1.464940 -0.950978      0   39.614503 -71.334278  -83.133270      0   \n",
       "27   -0.175132  1.464940      1   38.865152 -63.337490  -81.208906      0   \n",
       "28    0.990061 -0.175132      0   44.743966 -35.570488  -56.874785      0   \n",
       "29   -0.359279  0.990061      1   42.854432 -44.960958  -60.979892      0   \n",
       "...        ...       ...    ...         ...        ...         ...    ...   \n",
       "2633  0.755869 -1.192800      0   55.170071 -54.807972   14.485357      0   \n",
       "2634 -1.327655  0.755869      1   53.039260 -62.430782    7.920634      0   \n",
       "2635  1.137868 -1.327655      1   54.433649 -56.822515  -13.156981      0   \n",
       "2636 -0.636214  1.137868      0   55.645349 -52.031241   13.394462      0   \n",
       "2637 -2.415039 -0.636214      1   48.174375 -77.977607  -67.904419      0   \n",
       "2638  1.089952 -2.415039      0   51.154473 -67.029243  -69.238676      0   \n",
       "2639 -1.907988  1.089952      1   44.448649 -93.381008 -115.774855      0   \n",
       "2640  1.431194 -1.907988      1   50.053006 -70.039458  -87.297460      0   \n",
       "2641  1.438323  1.431194      0   52.003870 -45.147983  -48.729201      0   \n",
       "2642  0.220517  1.438323      1   51.230469 -49.555041  -33.941951      0   \n",
       "2643  0.229911  0.220517      1   52.139453 -44.328993  -17.320503      0   \n",
       "2644  0.676755  0.229911      0   56.485127 -19.756098   25.121030      0   \n",
       "2645 -0.848040  0.676755      1   52.087881 -37.912450    5.015310      0   \n",
       "2646  0.558224 -0.848040      0   53.815773 -25.949576   24.544878      0   \n",
       "2647 -1.550380  0.558224      1   49.865951 -50.347507  -10.954631      0   \n",
       "2648  2.081407 -1.550380      1   53.613791 -17.833361   27.089955      0   \n",
       "2649 -0.689799  2.081407      1   53.719751 -33.169603  106.312115      0   \n",
       "2650  3.707704 -0.689799      1   59.060293  -2.787436  147.748181      0   \n",
       "2651 -0.974610  3.707704      0   61.038706  -9.581031  233.368585      0   \n",
       "2652  0.104869 -0.974610      0   59.205131 -16.027187  172.361282      0   \n",
       "2653 -0.427009  0.104869      1   58.330379 -20.220076  138.302156      0   \n",
       "2654  0.648348 -0.427009      1   58.424398 -24.462067  109.492453      0   \n",
       "2655 -0.031976  0.648348      1   60.155923 -14.919670  128.145971      0   \n",
       "2656  0.489887 -0.031976      0   61.926798  -4.231126  120.792231      0   \n",
       "2657 -1.567595  0.489887      0   56.180878 -27.070326   79.702496      0   \n",
       "2658 -0.323141 -1.567595      1   53.425799 -38.857188   40.335622      0   \n",
       "2659  0.309212 -0.323141      0   54.924758 -31.435209   40.728236      0   \n",
       "2660 -0.531522  0.309212      1   51.718310 -44.711313   14.907147      0   \n",
       "2661 -0.079654 -0.531522      0   53.975399 -37.086666   23.444314      0   \n",
       "2662       NaN -0.079654      0   50.399213 -70.217241  -41.256430      0   \n",
       "\n",
       "      rtf  ccitf  \n",
       "0       1      0  \n",
       "1       2      0  \n",
       "2       2      0  \n",
       "3       2      0  \n",
       "4       2      0  \n",
       "5       2      0  \n",
       "6       2      1  \n",
       "7       2      0  \n",
       "8       2      1  \n",
       "9       2      1  \n",
       "10      0      0  \n",
       "11      2      0  \n",
       "12      0      0  \n",
       "13      1      2  \n",
       "14      1      2  \n",
       "15      1      2  \n",
       "16      1      2  \n",
       "17      0      2  \n",
       "18      1      2  \n",
       "19      1      2  \n",
       "20      0      2  \n",
       "21      0      0  \n",
       "22      0      0  \n",
       "23      1      0  \n",
       "24      1      2  \n",
       "25      1      2  \n",
       "26      0      0  \n",
       "27      0      0  \n",
       "28      0      0  \n",
       "29      0      0  \n",
       "...   ...    ...  \n",
       "2633    0      0  \n",
       "2634    0      0  \n",
       "2635    0      0  \n",
       "2636    0      0  \n",
       "2637    0      0  \n",
       "2638    0      0  \n",
       "2639    1      2  \n",
       "2640    0      0  \n",
       "2641    0      0  \n",
       "2642    0      0  \n",
       "2643    0      0  \n",
       "2644    2      0  \n",
       "2645    0      0  \n",
       "2646    0      0  \n",
       "2647    0      0  \n",
       "2648    2      0  \n",
       "2649    0      1  \n",
       "2650    2      1  \n",
       "2651    2      1  \n",
       "2652    2      1  \n",
       "2653    0      1  \n",
       "2654    0      1  \n",
       "2655    2      1  \n",
       "2656    2      1  \n",
       "2657    0      0  \n",
       "2658    0      0  \n",
       "2659    0      0  \n",
       "2660    0      0  \n",
       "2661    0      0  \n",
       "2662    0      0  \n",
       "\n",
       "[2663 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2661"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n"
     ]
    }
   ],
   "source": [
    "test=int(len(df)*0.20)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.column_stack((df.ho,df.lo,df.co,df.hl, df.Open1,df.Open2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2661, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://analyticsindiamag.com/hands-on-guide-to-lstm-recurrent-neural-network-for-stock-market-prediction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[]\n",
    "for i in range(b,len(X)):\n",
    "    t.append(X[i-b:i].reshape(b,6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputF=np.asarray(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2646, 15, 6, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.67083184  0.         -1.46940926  1.67083184  1.47515777\n",
      "   -1.11692873]\n",
      "  [ 0.          0.58613718  0.11847483  0.589593   -0.18744137\n",
      "    1.47515777]\n",
      "  [ 0.28652448  0.17198679 -0.08481021  0.4593012   0.06049025\n",
      "   -0.18744137]\n",
      "  ...\n",
      "  [ 0.10402081  2.16165285  2.01840897  2.31573175 -2.02123627\n",
      "   -1.08007105]\n",
      "  [ 0.          2.23243315  2.08477732  2.28340872 -2.06438053\n",
      "   -2.02123627]\n",
      "  [ 0.80363349  0.03272772 -0.21386269  0.83663502  0.19901525\n",
      "   -2.06438053]]\n",
      "\n",
      " [[ 0.          0.58613718  0.11847483  0.589593   -0.18744137\n",
      "    1.47515777]\n",
      "  [ 0.28652448  0.17198679 -0.08481021  0.4593012   0.06049025\n",
      "   -0.18744137]\n",
      "  [ 0.39030683  0.62340084 -0.33818586  1.02006677  0.33383474\n",
      "    0.06049025]\n",
      "  ...\n",
      "  [ 0.          2.23243315  2.08477732  2.28340872 -2.06438053\n",
      "   -2.02123627]\n",
      "  [ 0.80363349  0.03272772 -0.21386269  0.83663502  0.19901525\n",
      "   -2.06438053]\n",
      "  [ 0.88060024  0.38988364  0.01039268  1.27545668 -0.01039268\n",
      "    0.19901525]]\n",
      "\n",
      " [[ 0.28652448  0.17198679 -0.08481021  0.4593012   0.06049025\n",
      "   -0.18744137]\n",
      "  [ 0.39030683  0.62340084 -0.33818586  1.02006677  0.33383474\n",
      "    0.06049025]\n",
      "  [ 0.1225675   0.49093293 -0.11115966  0.61652717  0.13113949\n",
      "    0.33383474]\n",
      "  ...\n",
      "  [ 0.80363349  0.03272772 -0.21386269  0.83663502  0.19901525\n",
      "   -2.06438053]\n",
      "  [ 0.88060024  0.38988364  0.01039268  1.27545668 -0.01039268\n",
      "    0.19901525]\n",
      "  [ 0.59611342  0.88215743 -0.41072127  1.4914276   0.41817412\n",
      "   -0.01039268]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.1595949   0.         -1.11920419  1.1595949   0.67675468\n",
      "    0.22991142]\n",
      "  [ 0.01115666  1.16700892  1.07683774  1.19207722 -0.84804041\n",
      "    0.67675468]\n",
      "  [ 0.61437116  0.51564638 -0.45170897  1.13587463  0.55822365\n",
      "   -0.84804041]\n",
      "  ...\n",
      "  [ 0.78539847  0.11322122 -0.67579596  0.89963827  0.48988745\n",
      "   -0.03197568]\n",
      "  [ 0.06632633  1.46880869  1.1264318   1.55801935 -1.56759536\n",
      "    0.48988745]\n",
      "  [ 0.34782209  0.49202413  0.23939453  0.8439989  -0.32314065\n",
      "   -1.56759536]]\n",
      "\n",
      " [[ 0.01115666  1.16700892  1.07683774  1.19207722 -0.84804041\n",
      "    0.67675468]\n",
      "  [ 0.61437116  0.51564638 -0.45170897  1.13587463  0.55822365\n",
      "   -0.84804041]\n",
      "  [ 0.03203449  2.18973715  1.49006044  2.27151178 -1.55037959\n",
      "    0.55822365]\n",
      "  ...\n",
      "  [ 0.06632633  1.46880869  1.1264318   1.55801935 -1.56759536\n",
      "    0.48988745]\n",
      "  [ 0.34782209  0.49202413  0.23939453  0.8439989  -0.32314065\n",
      "   -1.56759536]\n",
      "  [ 0.67223697  0.07845682 -0.51838067  0.75128322  0.30921173\n",
      "   -0.32314065]]\n",
      "\n",
      " [[ 0.61437116  0.51564638 -0.45170897  1.13587463  0.55822365\n",
      "   -0.84804041]\n",
      "  [ 0.03203449  2.18973715  1.49006044  2.27151178 -1.55037959\n",
      "    0.55822365]\n",
      "  [ 1.59970849  0.20571775 -1.49842714  1.80914798  2.08140688\n",
      "   -1.55037959]\n",
      "  ...\n",
      "  [ 0.34782209  0.49202413  0.23939453  0.8439989  -0.32314065\n",
      "   -1.56759536]\n",
      "  [ 0.67223697  0.07845682 -0.51838067  0.75128322  0.30921173\n",
      "   -0.32314065]\n",
      "  [ 0.10324611  0.63227201  0.5660499   0.74019819 -0.53152165\n",
      "    0.30921173]]]\n"
     ]
    }
   ],
   "source": [
    "inputF = array(inputF).reshape(len(inputF), b, 6)\n",
    "print(inputF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2646, 15, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df[['label']][b:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = np.array(df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2646, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical#one-hot encode target column\n",
    "output = to_categorical(Y)\n",
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2646, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 15, 200)           165600    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 15, 100)           120400    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 15, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 25)                7600      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 324,552\n",
      "Trainable params: 324,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, activation='relu', return_sequences=True, input_shape=(b, 6)))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# checkpoint\n",
    "filepath=\"models/model{epoch:02d}\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2114 samples, validate on 532 samples\n",
      "Epoch 1/100\n",
      "2114/2114 [==============================] - 11s 5ms/step - loss: 8.5965 - accuracy: 0.5388 - val_loss: 8.7184 - val_accuracy: 0.5508\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.55075, saving model to models/model01\n",
      "Epoch 2/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7241 - accuracy: 0.4806 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.55075\n",
      "Epoch 3/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.55075\n",
      "Epoch 4/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.55075\n",
      "Epoch 5/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.55075\n",
      "Epoch 6/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.55075\n",
      "Epoch 7/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.55075\n",
      "Epoch 8/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.55075\n",
      "Epoch 9/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.55075\n",
      "Epoch 10/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.55075\n",
      "Epoch 11/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.55075\n",
      "Epoch 12/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.55075\n",
      "Epoch 13/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.55075\n",
      "Epoch 14/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.55075\n",
      "Epoch 15/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.55075\n",
      "Epoch 16/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.55075\n",
      "Epoch 17/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.55075\n",
      "Epoch 18/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.55075\n",
      "Epoch 19/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.55075\n",
      "Epoch 20/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.55075\n",
      "Epoch 21/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.55075\n",
      "Epoch 22/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.55075\n",
      "Epoch 23/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.55075\n",
      "Epoch 24/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.55075\n",
      "Epoch 25/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.55075\n",
      "Epoch 26/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.55075\n",
      "Epoch 27/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.55075\n",
      "Epoch 28/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.55075\n",
      "Epoch 29/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.55075\n",
      "Epoch 30/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.55075\n",
      "Epoch 31/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.55075\n",
      "Epoch 32/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.55075\n",
      "Epoch 33/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.55075\n",
      "Epoch 34/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.55075\n",
      "Epoch 35/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.55075\n",
      "Epoch 36/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.55075\n",
      "Epoch 37/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.55075\n",
      "Epoch 38/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.55075\n",
      "Epoch 39/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.55075\n",
      "Epoch 40/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.55075\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.55075\n",
      "Epoch 42/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.55075\n",
      "Epoch 43/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.55075\n",
      "Epoch 44/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.55075\n",
      "Epoch 45/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.55075\n",
      "Epoch 46/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.55075\n",
      "Epoch 47/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.55075\n",
      "Epoch 48/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.55075\n",
      "Epoch 49/100\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.55075\n",
      "Epoch 50/100\n",
      "2114/2114 [==============================] - 8s 4ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.55075\n",
      "Epoch 51/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.55075\n",
      "Epoch 52/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.55075\n",
      "Epoch 53/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.55075\n",
      "Epoch 54/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.55075\n",
      "Epoch 55/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.55075\n",
      "Epoch 56/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.55075\n",
      "Epoch 57/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.55075\n",
      "Epoch 58/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.55075\n",
      "Epoch 59/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.55075\n",
      "Epoch 60/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.55075\n",
      "Epoch 61/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.55075\n",
      "Epoch 62/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.55075\n",
      "Epoch 63/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.55075\n",
      "Epoch 64/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.55075\n",
      "Epoch 65/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.55075\n",
      "Epoch 66/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.55075\n",
      "Epoch 67/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.55075\n",
      "Epoch 68/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.55075\n",
      "Epoch 69/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.55075\n",
      "Epoch 70/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.55075\n",
      "Epoch 71/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.55075\n",
      "Epoch 72/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.55075\n",
      "Epoch 73/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.55075\n",
      "Epoch 74/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.55075\n",
      "Epoch 75/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.55075\n",
      "Epoch 76/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.55075\n",
      "Epoch 77/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.55075\n",
      "Epoch 78/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.55075\n",
      "Epoch 79/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.55075\n",
      "Epoch 80/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.55075\n",
      "Epoch 81/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.55075\n",
      "Epoch 82/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.55075\n",
      "Epoch 83/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.55075\n",
      "Epoch 84/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.55075\n",
      "Epoch 85/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.55075\n",
      "Epoch 86/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.55075\n",
      "Epoch 87/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.55075\n",
      "Epoch 88/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.55075\n",
      "Epoch 89/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.55075\n",
      "Epoch 90/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.55075\n",
      "Epoch 91/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.55075\n",
      "Epoch 92/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.55075\n",
      "Epoch 93/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.55075\n",
      "Epoch 94/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.55075\n",
      "Epoch 95/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.55075\n",
      "Epoch 96/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.55075\n",
      "Epoch 97/100\n",
      "2114/2114 [==============================] - 7s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.55075\n",
      "Epoch 98/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.55075\n",
      "Epoch 99/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.55075\n",
      "Epoch 100/100\n",
      "2114/2114 [==============================] - 6s 3ms/step - loss: 8.7376 - accuracy: 0.4579 - val_loss: 8.8771 - val_accuracy: 0.4492\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.55075\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "history=model.fit(inputF[:-test], output[:-test],  epochs=100,validation_data=(inputF[-test:], output[-test:]),\n",
    "                  shuffle=False,batch_size=32, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xu4XHV97/H3Z2b2JjuQEEhSLkkwAdMjASSGLVWkXhARqIWeggXUR4lwUnqkUBVt6GO9gFrweEPJ0SKGRuFwEaUntNFUrWg9XkjACEIEYgpkQyg7wSTcwr7M9/yx1uysTGb2TC5rT/bsz+t55sms28x3uXA++/f7rYsiAjMzs+EUWl2AmZnt/RwWZmbWkMPCzMwacliYmVlDDgszM2vIYWFmZg05LGzMkzRTUkgqNbHu+ZJ+OhJ1me1NHBY2qkh6VFKfpClV81elP/gzW1OZWXtzWNho9J/AeZUJSccAXa0rZ+/QTMvIbFc5LGw0+ibw7sz0e4BvZFeQtL+kb0jqlfSYpI9IKqTLipI+K2mDpLXAn9TY9uuS1kt6QtInJRWbKUzStyQ9JWmzpJ9IOiqzrEvS59J6Nkv6qaSudNmJkn4maZOkdZLOT+ffJenCzGds1w2WtqbeJ+kR4JF03jXpZ2yRdI+kP86sX5T0d5J+J+nZdPkMSYskfa5qX+6U9DfN7Le1P4eFjUa/ACZKOjL9ET8HuLFqnS8D+wOHA28gCZf56bL/AbwNeBXQDZxdte0SYAB4ebrOKcCFNOe7wGzgD4B7gZsyyz4LHAecABwIfBgoSzos3e7LwFRgLrCqye8D+DPgj4A56fSK9DMOBP4P8C1J49JlHyBplZ0OTATeC7yQ7vN5mUCdArwZuHkn6rB2FhF++TVqXsCjwMnAR4B/AE4Fvg+UgABmAkXgJWBOZru/BO5K3/87cFFm2SnptiXgoHTbrszy84Afpe/PB37aZK2T0s/dn+QPsxeBY2usdzlwR53PuAu4MDO93fenn39Sgzp+X/le4CHgzDrrrQbekr6/GFjW6uPt197zch+njVbfBH4CzKKqCwqYAnQCj2XmPQZMS98fCqyrWlbxMqADWC+pMq9QtX5NaSvnU8DbSVoI5Uw9+wDjgN/V2HRGnfnN2q42SR8kaQkdShImE9MaGn3XEuBdJOH7LuCa3ajJ2oy7oWxUiojHSAa6Twe+U7V4A9BP8sNfcRjwRPp+PcmPZnZZxTqSlsWUiJiUviZGxFE09g7gTJKWz/4krRwApTVtBY6osd26OvMBngfGZ6YPrrHO0K2j0/GJvwX+AjggIiYBm9MaGn3XjcCZko4FjgT+uc56NgY5LGw0u4CkC+b57MyIGARuAz4laYKkl5H01VfGNW4DLpE0XdIBwMLMtuuBfwM+J2mipIKkIyS9oYl6JpAEzUaSH/hPZz63DCwGPi/p0HSg+bWS9iEZ1zhZ0l9IKkmaLGluuukq4M8ljZf08nSfG9UwAPQCJUkfJWlZVFwPXClpthKvlDQ5rbGHZLzjm8C3I+LFJvbZxgiHhY1aEfG7iFhZZ/Ffk/xVvhb4KclA7+J02deA5cCvSQahq1sm7ybpxnqQpL//duCQJkr6BkmX1hPptr+oWn4ZcD/JD/IzwNVAISIeJ2khfTCdvwo4Nt3mC0Af8F8k3UQ3MbzlJIPlD6e1bGX7bqrPk4TlvwFbgK+z/WnHS4BjSALDbIgi/PAjM0tIej1JC2xm2hoyA9yyMLOUpA7gUuB6B4VVc1iYGZKOBDaRdLd9scXl2F7I3VBmZtaQWxZmZtZQ21yUN2XKlJg5c2aryzAzG1XuueeeDRExtdF6bRMWM2fOZOXKemdRmplZLZIea7yWu6HMzKwJDgszM2vIYWFmZg21zZhFLf39/fT09LB169ZWlzJixo0bx/Tp0+no6Gh1KWbWRto6LHp6epgwYQIzZ84kc7vpthURbNy4kZ6eHmbNmtXqcsysjbR1N9TWrVuZPHnymAgKAElMnjx5TLWkzGxktHVYAGMmKCrG2v6a2cho+7BoqDwIW9ZD3/ON1zUzG6McFlGG556Cvhf2+Edv3LiRuXPnMnfuXA4++GCmTZs2NN3X19fUZ8yfP5+HHnpoj9dmZrYz2nqAuylD3TZ7/oaKkydPZtWqVQB8/OMfZ7/99uOyyy7bbp3Kw9ALhdq5fcMNN+zxuszMdpZbFuQXFvWsWbOGo48+mosuuoh58+axfv16FixYQHd3N0cddRRXXHHF0Lonnngiq1atYmBggEmTJrFw4UKOPfZYXvva1/L000+PWM1mNraNmZbFJ+58gAef3FJ7Yd9zUNwCxbU79ZlzDp3Ix/70qF2q58EHH+SGG27gq1/9KgBXXXUVBx54IAMDA7zpTW/i7LPPZs6cOdtts3nzZt7whjdw1VVX8YEPfIDFixezcOHCWh9vZrZHuWXRIkcccQSvfvWrh6Zvvvlm5s2bx7x581i9ejUPPvjgDtt0dXVx2mmnAXDcccfx6KOPjlS5ZjbGjZmWRd0WQASsXwUTDoYJh4xYPfvuu+/Q+0ceeYRrrrmGu+++m0mTJvGud72r5rUSnZ2dQ++LxSIDAwMjUquZmVsWlQHuFj4xcMuWLUyYMIGJEyeyfv16li9f3rJazMxqGTMti+G19kK2efPmMWfOHI4++mgOP/xwXve617W0HjOzam3zDO7u7u6ofvjR6tWrOfLIIxtvvP7XMH4K7D8tp+pGVtP7bWZjnqR7IqK70XruhgKSlkV7hKaZWR4cFkMcFmZm9TgsIBnkdlaYmdXlsADcDWVmNjyHBaQtC4eFmVk9DoshDgszs3ocFgDkM2axJ25RDrB48WKeeuqpPV+gmVmTfFEepFdxt+YW5c1YvHgx8+bN4+CDD97TJZqZNcVhAbRigHvJkiUsWrSIvr4+TjjhBK699lrK5TLz589n1apVRAQLFizgoIMOYtWqVZxzzjl0dXVx9913b3ePKDOzkZBrWEg6FbgGKALXR8RVVcvPB/4X8EQ669qIuD6zfCKwGrgjIi7erWK+uxCeur/2sv4XktZFqWvnPvPgY+C0qxqvV+U3v/kNd9xxBz/72c8olUosWLCAW265hSOOOIINGzZw//1JnZs2bWLSpEl8+ctf5tprr2Xu3Lk7/V1mZntCbmEhqQgsAt4C9AArJC2NiOp7b986TBBcCfw4rxpb5Qc/+AErVqyguzu5wv7FF19kxowZvPWtb+Whhx7i0ksv5fTTT+eUU05pcaVmZok8WxbHA2siYi2ApFuAM4EdH9RQg6TjgIOA7wEN71vS0HAtgN6HQQWY8vLd/ppmRATvfe97ufLKK3dYdt999/Hd736XL33pS3z729/muuuuG5GazMyGk+fZUNOAdZnpnnRetbMk3SfpdkkzACQVgM8BHxruCyQtkLRS0sre3t5drzSnAe56Tj75ZG677TY2bNgAJGdNPf744/T29hIRvP3tb+cTn/gE9957LwATJkzg2WefHbH6zMyq5dmyqHXf7+pf5DuBmyPiJUkXAUuAk4D/CSyLiHVS/duHR8R1wHWQ3HV2V4osRxARiJE7j/iYY47hYx/7GCeffDLlcpmOjg6++tWvUiwWueCCC5J6JK6++moA5s+fz4UXXugBbjNrmdxuUS7ptcDHI+Kt6fTlABHxD3XWLwLPRMT+km4C/hgoA/sBncD/joi6D5ze1VuU9w+W2frUw4wrQcdBr2h6//ZmvkW5mTWr2VuU59myWAHMljSL5Gync4F3ZFeQdEhErE8nzyA584mIeGdmnfOB7uGCYncUKtfj+XYfZmZ15RYWETEg6WJgOcmps4sj4gFJVwArI2IpcImkM4AB4Bng/LzqqUcI30jQzGx4uV5nERHLgGVV8z6aeX85cHmDz/gn4J92owaGG/fYdnfy9giLdnnyoZntXdr63lDjxo1j48aNw/6ASiIQaoMf2Yhg48aNjBs3rtWlmFmbaevbfUyfPp2enh4anVb74qan6dQAxU2jPzvHjRvH9OnTW12GmbWZtg6Ljo4OZs2a1XC9Oz/+t5zY+TAH/N1vR6AqM7PRZ/T/Kb0HhIqoPNjqMszM9loOCyAKJQox0OoyzMz2Wg4LIApFhFsWZmb1OCwAVKIQDgszs3ocFgAFh4WZ2XAcFgDFIkWHhZlZXQ4LSFoWHrMwM6vLYQGoUKLEoG8maGZWh8MCoJBemxjl1tZhZraXclgAKnYkb8q+1sLMrBaHBUk3FOCwMDOrw2EBqOiwMDMbjsMCKAyFhc+IMjOrxWFBNizcsjAzq8VhgQe4zcwacViwrWUx0N/X4krMzPZODgu2hUX/QH+LKzEz2zs5LIBCKemG6u9zWJiZ1eKwIBMW7oYyM6vJYQGUKt1Q/W5ZmJnV4rAAipWWhccszMxqcliwLSwGHRZmZjU5LICiT501MxuWwwIopS2LAbcszMxqclgAxY60G8oD3GZmNTksyLQsBn27DzOzWhwWuBvKzKyRXMNC0qmSHpK0RtLCGsvPl9QraVX6ujCdP1fSzyU9IOk+SefkWWdHpRtqwC0LM7NaSnl9sKQisAh4C9ADrJC0NCIerFr11oi4uGreC8C7I+IRSYcC90haHhGb8qi11OFTZ83MhpNny+J4YE1ErI2IPuAW4MxmNoyIhyPikfT9k8DTwNS8Ch1qWQw6LMzMaskzLKYB6zLTPem8amelXU23S5pRvVDS8UAn8LsayxZIWilpZW9v7y4XWip1AlB2N5SZWU15hoVqzIuq6TuBmRHxSuAHwJLtPkA6BPgmMD8iyjt8WMR1EdEdEd1Tp+56w6OjM2lZlN0NZWZWU55h0QNkWwrTgSezK0TExoh4KZ38GnBcZZmkicC/Ah+JiF/kWCcdHWnLwqfOmpnVlGdYrABmS5olqRM4F1iaXSFtOVScAaxO53cCdwDfiIhv5VgjAJ0eszAzG1ZuZ0NFxICki4HlQBFYHBEPSLoCWBkRS4FLJJ0BDADPAOenm/8F8HpgsqTKvPMjYlUetaqQdkO5ZWFmVlNuYQEQEcuAZVXzPpp5fzlweY3tbgRuzLO27RSKyfc6LMzMavIV3ACFJDPL7oYyM6vJYQFDYeGWhZlZbQ4LcFiYmTXgsIBtYVF2WJiZ1eKwACgUKCNwWJiZ1eSwSA1SdMvCzKwOh0WqTBE8ZmFmVpPDIlVW0d1QZmZ1OCxSgypCDLa6DDOzvZLDIlWmiNyyMDOryWGRCndDmZnV5bBIlQtFVHY3lJlZLQ6LVKiIwi0LM7NaGoaFpIslHTASxbRSqIQ8wG1mVlMzLYuDgRWSbpN0qqRaj0sd9ULuhjIzq6dhWETER4DZwNdJHk70iKRPSzoi59pGVBSSlkVE9WPCzcysqTGLSH5Bn0pfA8ABwO2SPpNjbSMqVKTIIANlh4WZWbWGT8qTdAnwHmADcD3woYjol1QAHgE+nG+JI6RQosQgfQNlOooe9zczy2rmsapTgD+PiMeyMyOiLOlt+ZQ18qJQpEiZvoEy++7T6mrMzPYuzfwJvQx4pjIhaYKkPwKIiNV5FTbiKi2LwXKrKzEz2+s0ExZfAZ7LTD+fzmsvhRJFJS0LMzPbXjNhocicIhQRZZrrvhpVlLYsXnJYmJntoJmwWCvpEkkd6etSYG3ehY24Qokig/S7G8rMbAfNhMVFwAnAE0AP8EfAgjyLagUVS5RwN5SZWS0Nu5Mi4mng3BGopaVUTFoWL7plYWa2g2ausxgHXAAcBYyrzI+I9+ZY14hLxizcsjAzq6WZbqhvktwf6q3Aj4HpwLN5FtUKlZaFw8LMbEfNhMXLI+LvgecjYgnwJ8Ax+ZY18gpFnw1lZlZPM2HRn/67SdLRwP7AzNwqapFCsSO5zsJjFmZmO2jmeonr0udZfARYCuwH/H2uVbVApWXhbigzsx0N27JIbxa4JSJ+HxE/iYjDI+IPIuIfm/nw9PkXD0laI2lhjeXnS+qVtCp9XZhZ9h5Jj6Sv9+z0nu2kQrFj6N5QZma2vWFbFunNAi8GbtvZD5ZUBBYBbyG5PmOFpKUR8WDVqrdGxMVV2x4IfAzoBgK4J9329ztbR7MKpUrLwg9AMjOr1syYxfclXSZphqQDK68mtjseWBMRayOiD7gFOLPJut4KfD8inkkD4vvAqU1uu0uGWhYeszAz20EzYxaV6ynel5kXwOENtpsGrMtMV67+rnaWpNcDDwPvj4h1dbadVr2hpAWkV5MfdthhDcoZ3raWhcPCzKxaM49VnVXj1SgoAGo9q7v6MXR3AjMj4pXAD4AlO7EtEXFdRHRHRPfUqVObKKm+YrHD11mYmdXRzBXc7641PyK+0WDTHmBGZno68GTVZ2zMTH4NuDqz7Rurtr2rUa27o3IF90vuhjIz20Ez3VCvzrwfB7wZuBdoFBYrgNmSZpHchPBc4B3ZFSQdEhHr08kzgMrDlJYDn05P2QU4Bbi8iVp3XaFEQUFf/0CuX2NmNho1cyPBv85OS9qf5BYgjbYbSM+kWg4UgcUR8YCkK4CVEbEUuETSGcAAydP4zk+3fUbSlSSBA3BFRDyzw5fsSYUiAIP9/Q1WNDMbe3blIUYvALObWTEilpE8ljU776OZ95dTp8UQEYuBxbtQ364pJP9TDAw4LMzMqjUzZnEn2waXC8AcduG6i71e2rJwWJiZ7aiZlsVnM+8HgMcioienelonbVmUBx0WZmbVmgmLx4H1EbEVQFKXpJkR8WiulY20NCwG3bIwM9tBM1dwfwvInk86mM5rL0PdUD4bysysWjNhUUpv1wFA+r4zv5JaxC0LM7O6mgmL3vT0VgAknQlsyK+kFqmExaBbFmZm1ZoZs7gIuEnStel0D1Dzqu5RrTLA7ZaFmdkOmrko73fAayTtBygi2u7528DQmEXZYxZmZjto2A0l6dOSJkXEcxHxrKQDJH1yJIobUZWWRdktCzOzas2MWZwWEZsqE+nzJU7Pr6QWGeqGcsvCzKxaM2FRlLRPZUJSF7DPMOuPTkMX5TkszMyqNTPAfSPwQ0k3pNPz2fbcifaRjlmEw8LMbAfNDHB/RtJ9wMkkDyX6HvCyvAsbcb7dh5lZXc10QwE8RXIV91kkz7NYPfzqo1AaFlEeIGKHh/KZmY1pdVsWkv6Q5IFF5wEbgVtJTp190wjVNrLSsChSpn8w6CzVerKrmdnYNFw31G+B/wD+NCLWAEh6/4hU1QppWJQYpG+wTGep2UaXmVn7G+4X8SyS7qcfSfqapDeTjFm0p3SAu8ggfQN+DreZWVbdsIiIOyLiHOAVwF3A+4GDJH1F0ikjVN/IGWpZlB0WZmZVGva1RMTzEXFTRLwNmA6sAhbmXtlIGxqzcMvCzKzaTnXMR8QzEfGPEXFSXgW1TLZlMeiwMDPL8ihuhccszMzqclhUVFoWGnTLwsysisOiInOdhVsWZmbbc1hUZK+zcFiYmW3HYVGRbVkMDra4GDOzvYvDoiId4HbLwsxsRw6Lisx1Fi85LMzMtuOwqPAV3GZmdTksKrJXcPvUWTOz7TgsKpT8T1GSWxZmZtVyDQtJp0p6SNIaSXXvJyXpbEkhqTud7pC0RNL9klZLujzPOtMiiELJV3CbmdWQW1hIKgKLgNOAOcB5kubUWG8CcAnwy8zstwP7RMQxwHHAX0qamVetQwolj1mYmdWQZ8vieGBNRKyNiD7gFuDMGutdCXwG2JqZF8C+kkpAF9AHbMmxVgBUKNFZKPPcSwN5f5WZ2aiSZ1hMA9ZlpnvSeUMkvQqYERH/UrXt7cDzwHrgceCzEfFM9RdIWiBppaSVvb29u19xocj4UrDphf7d/ywzszaSZ1jUeqpeDC2UCsAXgA/WWO94YBA4FJgFfFDS4Tt8WMR1EdEdEd1Tp07d/YoLJcaXYPOLDgszs6zhnsG9u3qAGZnp6cCTmekJwNHAXZIADgaWSjoDeAfwvYjoB56W9P+AbmBtjvVCoURXMdj0Yl+uX2NmNtrk2bJYAcyWNEtSJ3AusLSyMCI2R8SUiJgZETOBXwBnRMRKkq6nk5TYF3gN8Nsca00USnS5G8rMbAe5hUVEDAAXA8uB1cBtEfGApCvS1sNwFgH7Ab8hCZ0bIuK+vGodUigyrhDuhjIzq5JnNxQRsQxYVjXvo3XWfWPm/XMkp8+OrEKJcbhlYWZWzVdwZxVK7FMMXuwf5KUB36bczKzCYZGVXmcBPiPKzCzLYZFVKLKPkrN7N7srysxsSK5jFqNOoUQHSctik1sWZmZD3LLIKpToVBoWblmYmQ1xWGQVSnTIYxZmZtUcFlmFEiUlZ0FtesFXcZuZVTgssgpFilGmILcszMyyHBZZhRKKAfbv6vCYhZlZhsMiq1CCchoWblmYmQ1xWGQVSlAeZP/xne6GMjPLcFhkFYpQHmBSVwebPcBtZjbEYZGVdkNNGu9uKDOzLIdFViUsPMBtZrYdh0VWZcyiq4MtW/spl6PxNmZmY4DDIkuF5Gyo8Z1EwLNbB1pdkZnZXsFhkZXphgL8LG4zs5TDIiszwA2+maCZWYXDIqtQgnJ5W1j4jCgzM8Bhsb30Oov9uzoB3x/KzKzCYZGVud0H4AvzzMxSDousqrDwmIWZWcJhkVUoQQzSWRT7dhY9ZmFmlnJYZBXSR5KXB5k0vtMtCzOzlMMiq1BM/k27ojzAbWaWcFhkDbUsKmHhAW4zM3BYbC8TFpPG+2aCZmYVDous7cYsfJtyM7MKh0XWdmMWnWx+oZ8I33nWzMxhkVXVDdU3WGZrf7m1NZmZ7QVyDQtJp0p6SNIaSQuHWe9sSSGpOzPvlZJ+LukBSfdLGpdnrcAOA9zgO8+amUGOYSGpCCwCTgPmAOdJmlNjvQnAJcAvM/NKwI3ARRFxFPBGIP8BhGzLwldxm5kNybNlcTywJiLWRkQfcAtwZo31rgQ+A2zNzDsFuC8ifg0QERsjYjDHWhNDYxaD7O/blJuZDckzLKYB6zLTPem8IZJeBcyIiH+p2vYPgZC0XNK9kj5c6wskLZC0UtLK3t7e3a94u5aF7zxrZlaRZ1ioxryhU4skFYAvAB+ssV4JOBF4Z/rvf5f05h0+LOK6iOiOiO6pU6fufsVVA9yAL8wzMyPfsOgBZmSmpwNPZqYnAEcDd0l6FHgNsDQd5O4BfhwRGyLiBWAZMC/HWhM1wsLdUGZmyV/weVkBzJY0C3gCOBd4R2VhRGwGplSmJd0FXBYRKyX9DviwpPFAH/AGklZIvjIX5XV1FOkoiltXruOex36f+1ebme2qWVP35fLTjsz1O3ILi4gYkHQxsBwoAosj4gFJVwArI2LpMNv+XtLnSQIngGUR8a951Tokc1GeJM6aN51V6zbx+DMv5P7VZma7anxnMffvyLNlQUQsI+lCys77aJ1131g1fSPJ6bMjJ9MNBXDVWa8c0a83M9tb+QrurKqwMDOzhMMiKzNmYWZm2zgssjJjFmZmto3DIsvdUGZmNTksshwWZmY1OSyyHBZmZjU5LLIyNxI0M7NtHBZZblmYmdXksMhyWJiZ1eSwyHJYmJnV5LDI8kV5ZmY1OSyyfFGemVlNDossd0OZmdXksMhyWJiZ1ZTrLcpHnUpY/HwR3Hdra2sxM2vWQUfB2Ytz/QqHRVaxBK//EGx4uNWVmJk1b9LLcv8Kh0W1kz7S6grMzPY6HrMwM7OGHBZmZtaQw8LMzBpyWJiZWUMOCzMza8hhYWZmDTkszMysIYeFmZk1pIhodQ17hKRe4LHd+IgpwIY9VM5oMRb3Gcbmfo/FfYaxud87u88vi4ipjVZqm7DYXZJWRkR3q+sYSWNxn2Fs7vdY3GcYm/ud1z67G8rMzBpyWJiZWUMOi22ua3UBLTAW9xnG5n6PxX2GsbnfueyzxyzMzKwhtyzMzKwhh4WZmTU05sNC0qmSHpK0RtLCVteTF0kzJP1I0mpJD0i6NJ1/oKTvS3ok/feAVte6p0kqSvqVpH9Jp2dJ+mW6z7dK6mx1jXuapEmSbpf02/SYv7bdj7Wk96f/bf9G0s2SxrXjsZa0WNLTkn6TmVfz2CrxpfT37T5J83b1e8d0WEgqAouA04A5wHmS5rS2qtwMAB+MiCOB1wDvS/d1IfDDiJgN/DCdbjeXAqsz01cDX0j3+ffABS2pKl/XAN+LiFcAx5Lsf9sea0nTgEuA7og4GigC59Kex/qfgFOr5tU7tqcBs9PXAuAru/qlYzosgOOBNRGxNiL6gFuAM1tcUy4iYn1E3Ju+f5bkx2Mayf4uSVdbAvxZayrMh6TpwJ8A16fTAk4Cbk9Xacd9ngi8Hvg6QET0RcQm2vxYkzwmuktSCRgPrKcNj3VE/AR4pmp2vWN7JvCNSPwCmCTpkF353rEeFtOAdZnpnnReW5M0E3gV8EvgoIhYD0mgAH/Quspy8UXgw0A5nZ4MbIqIgXS6HY/54UAvcEPa/Xa9pH1p42MdEU8AnwUeJwmJzcA9tP+xrqh3bPfYb9xYDwvVmNfW5xJL2g/4NvA3EbGl1fXkSdLbgKcj4p7s7BqrttsxLwHzgK9ExKuA52mjLqda0j76M4FZwKHAviRdMNXa7Vg3ssf+ex/rYdEDzMhMTweebFEtuZPUQRIUN0XEd9LZ/1Vplqb/Pt2q+nLwOuAMSY+SdDGeRNLSmJR2VUB7HvMeoCcifplO304SHu18rE8G/jMieiOiH/gOcALtf6wr6h3bPfYbN9bDYgUwOz1jopNkQGxpi2vKRdpX/3VgdUR8PrNoKfCe9P17gP870rXlJSIuj4jpETGT5Nj+e0S8E/gRcHa6WlvtM0BEPAWsk/Tf0llvBh6kjY81SffTaySNT/9br+xzWx/rjHrHdinw7vSsqNcAmyvdVTtrzF/BLel0kr82i8DiiPhUi0vKhaQTgf8A7mdb//3fkYxb3AYcRvJ/uLdHRPXg2agn6Y3AZRHxNkmHk7Q0DgR+BbwrIl5qZX17mqS5JIP6ncBaYD7JH4dte6wlfQI4h+TMv18BF5L0z7fVsZZ0M/BGkluR/xfwMeCfqXFs0+C8luTsqReA+RGxcpe+d6yHhZmZNTbWu6HMzKwJDgszM2vIYWFmZg05LMzMrCGHhZmZNeSwMNsJkgYlrcq89tiV0ZJmZu8karY3KTVexcwyXoyezSRZAAABbUlEQVSIua0uwmykuWVhtgdIelTS1ZLuTl8vT+e/TNIP02cJ/FDSYen8gyTdIenX6euE9KOKkr6WPpfh3yR1tWynzDIcFmY7p6uqG+qczLItEXE8yRWzX0znXUtyi+hXAjcBX0rnfwn4cUQcS3LfpgfS+bOBRRFxFLAJOCvn/TFriq/gNtsJkp6LiP1qzH8UOCki1qY3bHwqIiZL2gAcEhH96fz1ETFFUi8wPXvrifTW8d9PH2CDpL8FOiLik/nvmdnw3LIw23Oizvt669SSvW/RIB5XtL2Ew8Jszzkn8+/P0/c/I7njLcA7gZ+m738I/BUMPSN84kgVabYr/FeL2c7pkrQqM/29iKicPruPpF+S/BF2XjrvEmCxpA+RPL1ufjr/UuA6SReQtCD+iuQJb2Z7JY9ZmO0B6ZhFd0RsaHUtZnlwN5SZmTXkloWZmTXkloWZmTXksDAzs4YcFmZm1pDDwszMGnJYmJlZQ/8fHBTmzhePQt0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"models/model95\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=model.predict(inputF[-test:])\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=np.argmax(output[-test:], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.28      0.37       239\n",
      "           1       0.58      0.79      0.67       293\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       532\n",
      "   macro avg       0.55      0.54      0.52       532\n",
      "weighted avg       0.55      0.56      0.53       532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report')\n",
    "target_names = ['Actual', 'Prediction']\n",
    "\n",
    "print(classification_report(actual, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jagdish/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jagdish/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/jagdish/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:1035: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._set_with(key, value)\n",
      "/home/jagdish/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df['y_pred']=5\n",
    "df['y_pred'][-test:]=y_pred\n",
    "df.to_csv(\"afterDJIA.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
